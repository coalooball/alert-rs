mod config;
mod db;
mod kafka;
mod models;

use crate::config::load_config;
use axum::{
    Router,
    extract::{State, Query},
    response::Json,
    routing::get,
};
use serde::{Deserialize, Serialize};
use std::net::SocketAddr;
use std::sync::Arc;
use tracing::info;
use tracing_subscriber;
use rbatis::RBatis;
use tower_http::cors::{CorsLayer, Any};
use tower_http::services::ServeDir;
use clap::Parser;

#[derive(Parser, Debug)]
#[command(name = "server", about = "Axum å‘Šè­¦æ¨é€æœåŠ¡å™¨")] 
struct Args {
    /// é‡ç½®æ•°æ®åº“ï¼ˆåˆ é™¤æ‰€æœ‰ä¸šåŠ¡è¡¨åé€€å‡ºï¼‰
    #[arg(long, default_value_t = false)]
    reset_db: bool,
}

#[tokio::main]
async fn main() {
    // åˆå§‹åŒ–æ—¥å¿—
    tracing_subscriber::fmt::init();

    // è§£æå‘½ä»¤è¡Œ
    let args = Args::parse();

    // è¯»å–é…ç½®
    let config = load_config("config.toml").expect("è¯»å–é…ç½®å¤±è´¥");

    // åˆå§‹åŒ–æ•°æ®åº“
    let rb = db::init_postgres(&config.postgres)
        .await
        .expect("Postgres åˆå§‹åŒ–å¤±è´¥");

    // è‹¥æŒ‡å®š --reset-dbï¼Œåˆ™åˆ é™¤è¡¨åé€€å‡º
    if args.reset_db {
        if let Err(e) = db::reset_database(&rb).await {
            eprintln!("æ•°æ®åº“é‡ç½®å¤±è´¥: {}", e);
            std::process::exit(1);
        }
        println!("âœ… æ•°æ®åº“å·²é‡ç½®ï¼ˆç›¸å…³è¡¨å·²åˆ é™¤ï¼‰ã€‚");
        return;
    }

    // å¯åŠ¨ Kafka æ¶ˆè´¹ä»»åŠ¡
    let kafka_cfg = config.kafka.clone();
    let topics_cfg = config.topics.clone();
    let rb_clone = rb.clone();
    tokio::spawn(async move {
        if let Err(e) = kafka::run_consumer(kafka_cfg, topics_cfg, rb_clone).await {
            tracing::error!("Kafka consumer stopped: {}", e);
        }
    });

    // åˆ›å»ºå…±äº«çŠ¶æ€
    let app_state = Arc::new(rb);

    // é…ç½® CORS
    let cors = CorsLayer::new()
        .allow_origin(Any)
        .allow_methods(Any)
        .allow_headers(Any);

    // API è·¯ç”±
    let api_routes = Router::new()
        .route("/api/network-attacks", get(get_network_attacks))
        .route("/api/malicious-samples", get(get_malicious_samples))
        .route("/api/host-behaviors", get(get_host_behaviors))
        .with_state(app_state);

    // é™æ€æ–‡ä»¶æœåŠ¡ - ä¸º SPA è·¯ç”±æä¾› index.html fallback
    let serve_dir = ServeDir::new("frontend/dist");

    // åˆå¹¶è·¯ç”±
    let app = Router::new()
        .merge(api_routes)
        .nest_service("/", serve_dir)
        .layer(cors);

    // æœåŠ¡å™¨åœ°å€
    let addr = SocketAddr::from(([0, 0, 0, 0], 3000));

    println!("â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—");
    println!("â•‘  ğŸ¦€ Axum å‘Šè­¦æ¨é€æœåŠ¡å™¨å¯åŠ¨æˆåŠŸï¼                       â•‘");
    println!("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•");
    println!();
    println!("ğŸŒ è®¿é—®åœ°å€:");
    println!("   ğŸ‘‰ å‰ç«¯ç•Œé¢: http://localhost:3000");
    println!("   ğŸ‘‰ API æ¥å£: http://localhost:3000/api/*");
    println!();
    println!("ğŸ“¥ å½“å‰æœªå¼€æ”¾ HTTP æ•°æ®æ¥æ”¶ç«¯ç‚¹ï¼ˆå·²åˆ‡æ¢ä¸º Kafka é€šé“ï¼‰");
    println!();
    println!("ğŸ’¡ æç¤ºï¼šä½¿ç”¨ generator CLI å·¥å…·å‘ Kafka å‘é€å‘Šè­¦æ•°æ®");
    println!("   cargo run --bin generator -- --help");
    println!();
    println!("   æŒ‰ Ctrl+C åœæ­¢æœåŠ¡");
    println!();

    info!("æœåŠ¡å™¨å¯åŠ¨åœ¨ http://localhost:3000ï¼ˆæ— è·¯ç”±ï¼‰");
    info!("Kafka brokers={}", config.kafka.brokers);

    // å¯åŠ¨æœåŠ¡å™¨
    let listener = tokio::net::TcpListener::bind(addr).await.unwrap();
    axum::serve(listener, app).await.unwrap();
}

// æŸ¥è¯¢å‚æ•°
#[derive(Deserialize)]
struct PageQuery {
    #[serde(default = "default_page")]
    page: u64,
    #[serde(default = "default_page_size")]
    page_size: u64,
}

fn default_page() -> u64 { 1 }
fn default_page_size() -> u64 { 20 }

// å“åº”ç»“æ„
#[derive(Serialize)]
struct PageResponse<T> {
    data: Vec<T>,
    total: u64,
    page: u64,
    page_size: u64,
}

// API å¤„ç†å‡½æ•°
async fn get_network_attacks(
    State(rb): State<Arc<RBatis>>,
    Query(params): Query<PageQuery>,
) -> Json<PageResponse<db::NetworkAttackRecord>> {
    match db::query_network_attacks(&rb, params.page, params.page_size).await {
        Ok((data, total)) => Json(PageResponse {
            data,
            total,
            page: params.page,
            page_size: params.page_size,
        }),
        Err(e) => {
            tracing::error!("Query network attacks failed: {}", e);
            Json(PageResponse {
                data: vec![],
                total: 0,
                page: params.page,
                page_size: params.page_size,
            })
        }
    }
}

async fn get_malicious_samples(
    State(rb): State<Arc<RBatis>>,
    Query(params): Query<PageQuery>,
) -> Json<PageResponse<db::MaliciousSampleRecord>> {
    match db::query_malicious_samples(&rb, params.page, params.page_size).await {
        Ok((data, total)) => Json(PageResponse {
            data,
            total,
            page: params.page,
            page_size: params.page_size,
        }),
        Err(e) => {
            tracing::error!("Query malicious samples failed: {}", e);
            Json(PageResponse {
                data: vec![],
                total: 0,
                page: params.page,
                page_size: params.page_size,
            })
        }
    }
}

async fn get_host_behaviors(
    State(rb): State<Arc<RBatis>>,
    Query(params): Query<PageQuery>,
) -> Json<PageResponse<db::HostBehaviorRecord>> {
    match db::query_host_behaviors(&rb, params.page, params.page_size).await {
        Ok((data, total)) => Json(PageResponse {
            data,
            total,
            page: params.page,
            page_size: params.page_size,
        }),
        Err(e) => {
            tracing::error!("Query host behaviors failed: {}", e);
            Json(PageResponse {
                data: vec![],
                total: 0,
                page: params.page,
                page_size: params.page_size,
            })
        }
    }
}
